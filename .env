# Model Configuration
OLLAMA_BASE_URL=http://localhost:11434
BASE_MODEL=llama3:8b
FINE_TUNED_MODEL=personal-assistant

# Vector Database
CHROMA_DB_PATH=./data/chroma_db
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Server Configuration
MCP_SERVER_HOST=localhost
MCP_SERVER_PORT=8000
API_KEY=your-secret-api-key-here

# Processing Configuration
CHUNK_SIZE=400
CHUNK_OVERLAP=50
TOP_K_RESULTS=5
